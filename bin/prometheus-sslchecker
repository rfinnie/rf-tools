#!/usr/bin/python3

# SPDX-FileComment: prometheus-sslchecker
# SPDX-FileCopyrightText: Copyright (C) 2021 Ryan Finnie
# SPDX-License-Identifier: MPL-2.0

# Sample sslchecker.yaml:
#
# hosts:
# - hostname: www.example.com
#   port: 443
# - hostname: www.implicit-443.example.com
# - hostname: smtp.example.com
#   port: 25
#   type: starttls
# - hostname: ftp.example.com
#   port: 21
#   type: auth_tls
# - hostname: imap.example.com
#   port: 993
# - hostname: mumble.example.com
#   port: 64738

import argparse
import binascii
import datetime
import logging
import os
import pathlib
import random
import socket
import ssl
import sys
import time

from cryptography import x509
from cryptography.hazmat.backends import default_backend
import prometheus_client
from prometheus_client import Gauge
import yaml


class BaseMetrics:
    prefix = "base"
    interval = 60
    registry = None
    args = None
    config = None
    needs_config = False
    collection_duration = None
    collection_errors = None

    def setup(self):
        pass

    def collect_metrics(self):
        pass

    def metrics_args(self, parser):
        pass

    def parse_args(self, argv=None):
        def _optional_path(string):
            return pathlib.Path(string) if string else None

        if argv is None:
            argv = sys.argv

        parser = argparse.ArgumentParser(
            formatter_class=argparse.ArgumentDefaultsHelpFormatter,
            prog=os.path.basename(argv[0]),
        )

        action_group = parser.add_mutually_exclusive_group(required=True)
        action_group.add_argument(
            "--http-daemon", action="store_true", help="Run an HTTP daemon"
        )
        action_group.add_argument(
            "--prom-daemon", action="store_true", help="Run a .prom-writing daemon"
        )
        action_group.add_argument(
            "--write", action="store_true", help="Write a .prom file"
        )
        action_group.add_argument(
            "--dump", action="store_true", help="Dump a .prom file to stdout"
        )

        parser.add_argument(
            "--prom-file",
            type=pathlib.Path,
            default="/var/lib/prometheus/node-exporter/{}.prom".format(self.prefix),
            help=".prom file to write",
            metavar="FILE",
        )
        parser.add_argument(
            "--http-port",
            type=int,
            default=(
                (binascii.crc32(self.prefix.encode("UTF-8")) & (65535 - 49152)) + 49152
            ),
            help="HTTP port number",
            metavar="PORT",
        )
        parser.add_argument(
            "--interval",
            type=float,
            default=self.interval,
            help="Seconds between collections",
            metavar="SECONDS",
        )
        parser.add_argument(
            "--interval-randomize",
            type=float,
            default=10,
            help="Randomize interval by +/- PERCENT percent, 0 to disable",
            metavar="PERCENT",
        )
        default_config_file = pathlib.Path(
            "/etc/prometheus/collectors/{}.yaml".format(self.prefix)
        )
        if (not self.needs_config) and (not default_config_file.exists()):
            default_config_file = None
        parser.add_argument(
            "--config",
            type=_optional_path,
            default=default_config_file,
            help="YAML configuration file",
            metavar="FILE",
        )

        self.metrics_args(parser)
        return parser.parse_args(args=argv[1:])

    def load_config(self):
        if not self.args.config:
            return {}
        with self.args.config.open() as f:
            return yaml.safe_load(f)

    def main(self):
        logging_level = logging.DEBUG if sys.stdin.isatty() else logging.INFO
        logging.basicConfig(level=logging_level)
        self.args = self.parse_args()
        self.interval = self.args.interval
        self.config = self.load_config()
        if self.args.http_daemon:
            self.registry = prometheus_client.REGISTRY
            self.collection_duration = prometheus_client.Summary(
                "{}_collection_duration_seconds".format(self.prefix),
                "Time spent collecting metrics",
                registry=self.registry,
            )
            self.collection_errors = prometheus_client.Counter(
                "{}_collection_errors_total".format(self.prefix),
                "Errors encountered while collecting metrics",
                registry=self.registry,
            )
        else:
            self.registry = prometheus_client.CollectorRegistry()
        self.setup()

        if self.args.http_daemon:
            prometheus_client.start_http_server(
                self.args.http_port, registry=self.registry
            )
            logging.info("HTTP server running on port {}".format(self.args.http_port))

        while True:
            logging.debug("Beginning collection run")
            try:
                if self.collection_duration:
                    with self.collection_duration.time():
                        self.collect_metrics()
                else:
                    self.collect_metrics()
            except Exception:
                if self.args.write or self.args.dump:
                    raise
                else:
                    logging.exception("Encountered an error during collection")
                if self.collection_errors:
                    self.collection_errors.inc()

            if self.args.prom_daemon or self.args.write:
                prometheus_client.write_to_textfile(
                    str(self.args.prom_file), registry=self.registry
                )
            elif self.args.dump:
                output = prometheus_client.generate_latest(registry=self.registry)
                print(output.decode("UTF-8"), end="")
            if self.args.write or self.args.dump:
                return

            if self.args.http_daemon or self.args.prom_daemon:
                sleep = random.uniform(
                    self.interval * (1 - (self.args.interval_randomize / 100.0)),
                    self.interval * (1 + (self.args.interval_randomize / 100.0)),
                )
                logging.debug("Sleeping for {}".format(sleep))
                time.sleep(sleep)


class Metrics(BaseMetrics):
    prefix = "sslchecker"
    needs_config = True
    full_check_complete = False
    spread_interval = 14400

    def setup(self):
        self.metrics = {}
        self.metrics["retrieval_time_seconds"] = Gauge(
            "{}_retrieval_time_seconds".format(self.prefix),
            "Last certificate retrieval time, seconds since epoch",
            ["server_hostname", "server_port"],
            registry=self.registry,
        )
        self.metrics["retrieval_success_boolean"] = Gauge(
            "{}_retrieval_success_boolean".format(self.prefix),
            "1 for successful retrieval, 0 for failure",
            ["server_hostname", "server_port"],
            registry=self.registry,
        )
        self.metrics["not_before_seconds"] = Gauge(
            "{}_not_before_seconds".format(self.prefix),
            "Not Before time of certificate, seconds since epoch",
            ["server_hostname", "server_port", "certificate_cn", "issuer_cn"],
            registry=self.registry,
        )
        self.metrics["not_after_seconds"] = Gauge(
            "{}_not_after_seconds".format(self.prefix),
            "Not After time of certificate, seconds since epoch",
            ["server_hostname", "server_port", "certificate_cn", "issuer_cn"],
            registry=self.registry,
        )
        self.metrics["serial_number"] = Gauge(
            "{}_serial_number".format(self.prefix),
            "Serial number of certificate",
            ["server_hostname", "server_port", "certificate_cn", "issuer_cn"],
            registry=self.registry,
        )

    def collect_metrics(self):
        if self.full_check_complete:
            hosts = []
            chance = 1.0 / (self.spread_interval / self.interval)
            for host in self.config["hosts"]:
                if random.random() < chance:
                    hosts.append(host)
            logging.debug("Checking {} random host(s)".format(len(hosts)))
        else:
            hosts = self.config["hosts"]
            logging.debug("Doing full check of all hosts")

        for host in hosts:
            hostname = host["hostname"]
            if "port" not in host:
                host["port"] = 443
            port = host["port"]
            try:
                res = self.check_host(host)
            except Exception:
                logging.exception("Error on {}:{}".format(hostname, port))
                self.metrics["retrieval_success_boolean"].labels(
                    hostname, str(port)
                ).set(0)
                continue
            self.metrics["retrieval_time_seconds"].labels(hostname, str(port)).set(
                float(time.time())
            )
            self.metrics["retrieval_success_boolean"].labels(hostname, str(port)).set(1)
            labels = (hostname, str(port), res[3], res[4])

            self.metrics["serial_number"].labels(*labels).set(res[0])
            self.metrics["not_before_seconds"].labels(*labels).set(res[1].timestamp())
            self.metrics["not_after_seconds"].labels(*labels).set(res[2].timestamp())

        if not self.full_check_complete:
            self.full_check_complete = True

    def check_host(self, host):
        hostname = host["hostname"]
        port = host["port"]
        now = datetime.datetime.now()
        addr = socket.getaddrinfo(hostname, port)[0]
        sock = socket.socket(addr[0], addr[1], addr[2])
        sock.settimeout(10)
        sock.connect(addr[4])
        if host.get("type") == "starttls":
            # Usually SMTP (port 25)
            sock.recv(1024)
            sock.send(b"STARTTLS\r\n")
            sock.recv(1024)
        elif host.get("type") == "auth_tls":
            # Usually FTP (port 21)
            sock.recv(1024)
            sock.send(b"AUTH TLS\r\n")
            sock.recv(1024)

        ssl_context = ssl.SSLContext()
        ssl_sock = ssl_context.wrap_socket(sock, server_hostname=hostname)
        der_data = ssl_sock.getpeercert(True)
        ssl_sock.close()
        cert = x509.load_der_x509_certificate(der_data, default_backend())
        subject_cn = ""
        issuer_cn = ""
        sans = []
        oid_cn = x509.ObjectIdentifier("2.5.4.3")
        oid_san = x509.ObjectIdentifier("2.5.29.17")
        for attribute in cert.subject:
            if attribute.oid == oid_cn:
                subject_cn = attribute.value
        for attribute in cert.issuer:
            if attribute.oid == oid_cn:
                issuer_cn = attribute.value
        for attribute in cert.extensions:
            if attribute.oid == oid_san:
                sans = sorted([x.value for x in attribute.value])
        logging.debug(
            "{}:{} ({}) expires in {}".format(
                hostname, port, subject_cn, (cert.not_valid_after - now)
            )
        )
        logging.debug("    Issuer: {}".format(issuer_cn))
        logging.debug("    SANs: {}".format(sans))
        return (
            cert.serial_number,
            cert.not_valid_before,
            cert.not_valid_after,
            subject_cn,
            issuer_cn,
            sans,
        )


if __name__ == "__main__":
    sys.exit(Metrics().main())
